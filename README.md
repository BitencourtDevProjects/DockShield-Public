![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python&logoColor=white)
![Shell](https://img.shields.io/badge/Shell-Bash-orange?logo=gnu-bash&logoColor=white)
![License](https://img.shields.io/badge/License-AGPLv3-green)
![MongoDB](https://img.shields.io/badge/MongoDB-6.0-green?logo=mongodb&logoColor=white)
![Version](https://img.shields.io/badge/Version-1.0.0-blue)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Mateus-blue?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/mateus-brito-bitencourt-497a30223)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Gabriel-blue?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/gabriel-brito-bitencourt-a847b922a)

![Logo Dockshield](./assets/Logo_Dockshield.png)

# Sum√°rio

- [üìå Vis√£o Geral](#-vis√£o-geral)
- [üèóÔ∏è Arquitetura do Sistema](#%EF%B8%8F-arquitetura-do-sistema)
  - [Diagrama de Fluxo e Componentes](#diagrama-de-fluxo-e-componentes)
  - [Fluxo de Execu√ß√£o e Processamento de Dados](#fluxo-de-execu%C3%A7%C3%A3o-e-processamento-de-dados)
  - [Tecnologias Principais](#tecnologias-principais)
- [üìã Requisitos](#-requisitos)
- [‚öôÔ∏è Instala√ß√£o](#%EF%B8%8F-instala%C3%A7%C3%A3o)
  - [Server A](#server-a)
  - [Server B](#server-b)
  - [Web Server](#web-server)
- [‚öôÔ∏è Configura√ß√£o](#%EF%B8%8F-configura%C3%A7%C3%A3o)
  - [Server A](#server-a-1)
  - [Server B](#server-b-1)
  - [Web Server](#web-server-1)
- [ü§î Como usar o DockShield?](#-como-usar-o-dockshield)
- [üóÇÔ∏è Estrutura do Programa](#%EF%B8%8F-estrutura-do-programa)
  - [‚û°Ô∏è Server A](#%EF%B8%8F-server-a)
  - [‚û°Ô∏è Server B](#%EF%B8%8F-server-b)
  - [‚û°Ô∏è Web Server](#%EF%B8%8F-web-server)
 - [üòÉ Autores](#-autores)
 - [üìù Licen√ßa](#-licen%C3%A7a)

# üìå Vis√£o Geral

**DockShield** √© um programa de **automatiza√ß√£o de an√°lises de cont√™ineres Docker**, que utiliza **LLMs (Large Language Models)** para interpretar e detalhar vulnerabilidades encontradas.  
O principal diferencial do projeto √© **a velocidade**, permitindo analisar **centenas de vulnerabilidades por dia**, oferecendo insights r√°pidos e confi√°veis para equipes de seguran√ßa.

O projeto √© organizado em **tr√™s m√≥dulos principais**, cada um em um diret√≥rio espec√≠fico:

| Diret√≥rio       | Fun√ß√£o                                                                                  |
|-----------------|----------------------------------------------------------------------------------------|
| **server_a/**   | Cont√©m os c√≥digos que devem ser executados no **servidor analisado**, onde as imagens Docker est√£o rodando. |
| **server_b/**   | Cont√©m os c√≥digos do **servidor de an√°lise**, respons√°vel por orquestrar a execu√ß√£o do Trivy, processar os resultados e gerar relat√≥rios detalhados. |
| **server_web/** | Cont√©m os c√≥digos para subir um **servidor web Apache**, permitindo a visualiza√ß√£o dos resultados das an√°lises em uma interface web. |

üí° **Resumo:** O DockShield conecta os tr√™s m√≥dulos para criar um fluxo de an√°lise altamente eficiente:  
**Imagens Docker ‚Üí An√°lise automatizada r√°pida ‚Üí Resultados acess√≠veis via web.**

---

# üèóÔ∏è Arquitetura do Sistema

O **DockShield** utiliza uma **Arquitetura Distribu√≠da Cliente-Servidor (Client-Server)**, implementada atrav√©s de tr√™s m√≥dulos logicamente separados que atuam em diferentes dom√≠nios de rede.

## Diagrama de Fluxo e Componentes

O diagrama a seguir ilustra o fluxo completo de dados, desde a requisi√ß√£o de an√°lise no **Client Server** at√© a persist√™ncia e visualiza√ß√£o dos relat√≥rios enriquecidos pela Intelig√™ncia Artificial.

![Diagrama do DockShield](assets/Diagrama_Dockshield.jpeg)

## Fluxo de Execu√ß√£o e Processamento de Dados

O sistema opera atrav√©s de um fluxo sequencial e automatizado no **Vulnerability Analysis Server**, acionado remotamente pelo cliente:

1.  **Inicia√ß√£o:** O **Client Server** (m√≥dulo `server_a/`), que hospeda o *daemon* **Docktransporter**, envia o **nome da imagem** desejada para an√°lise via **API** ao **Vulnerability Analysis Server** (`server_b/`).
2.  **Prepara√ß√£o:** O **Vulnerability Analysis Server** realiza o *pull* da imagem a partir do **Docker Hub** e executa o cont√™iner.
3.  **Varredura:** O *scanner* **Trivy** √© executado para identificar vulnerabilidades (CVEs, configura√ß√µes incorretas, etc.) e listar os resultados brutos.
4.  **Intelig√™ncia e Enriquecimento (O Core):** Os dados brutos s√£o enviados para a **AI API** para o **Vulnerability assessment using a Large Language Model (LLM)**. O LLM prov√™ contexto, severidade customizada e sugest√µes de remedia√ß√£o para cada vulnerabilidade.
5.  **Persist√™ncia:** O relat√≥rio final, agora enriquecido pela IA, √© persistido no banco de dados **Mongo DB** para acesso futuro.
6.  **Visualiza√ß√£o:** O **Web Interface** (`server_web/`) consulta o **Mongo DB** e apresenta os relat√≥rios de an√°lise (CVEs e AI Assessment) ao usu√°rio.


## Tecnologias Principais

O sistema foi desenvolvido utilizando **Python** como linguagem principal de *backend* e orquestra√ß√£o. As tecnologias espec√≠ficas s√£o:

* **Linguagem de Orquestra√ß√£o:** **Python**.
* **Banco de Dados (Persist√™ncia):** **Mongo DB** (escolhido por sua flexibilidade em armazenar documentos n√£o estruturados, ideal para os relat√≥rios din√¢micos do LLM).
* **Scanner:** **Trivy** (utilizado para varredura de cont√™ineres e sistemas de arquivos).
* **Intelig√™ncia:** **Large Language Model (LLM)**, acessado via **API**, para processamento de linguagem natural e enriquecimento de dados.

---

# üìã Requisitos

Para que o **DockShield** funcione corretamente, √© necess√°rio atender aos seguintes requisitos:

- **Servidor de banco de dados MongoDB**  
  - Para armazenar os relat√≥rios criados pela LLM e as CVEs.

- **Chave de API de LLM**  
  - Compat√≠vel com a biblioteca Python da OpenAI, usada para interpretar e resumir vulnerabilidades.

- **Chave de API do NVDLib**  
  - Necess√°ria para consultar a base de dados de vulnerabilidades NVD e obter informa√ß√µes detalhadas sobre cada CVE.

- **Tr√™s servidores rodando Ubuntu Server**  
  - **Server A:** servidor onde as imagens Docker que ser√£o analisadas est√£o rodando.  
  - **Server B:** servidor de an√°lise que processa os resultados.  
  - **Web Server:** servidor web Apache para visualiza√ß√£o dos resultados.
---

# ‚öôÔ∏è Instala√ß√£o

## Server A
O **Server A** √© o servidor onde as imagens Docker que ser√£o analisadas est√£o rodando.
### Passo 1: Clonar o reposit√≥rio
```bash
git clone https://github.com/BitencourtDevProjects/DockShield-Public.git
```
### Passo 2: Dar permiss√µes de execu√ß√£o para o instalador
```bash
sudo chmod u+x ./DockShield/server_a/install.sh
```
### Passo 3: Executar arquivo de instala√ß√£o
```bash
sudo ./DockShield/server_a/install.sh
```
## Server B
O "server B" √© o servidor que ir√° orquestrar a an√°lise das imagens pelas LLMs
### Passo 1: Clonar o reposit√≥rio
```bash
git clone https://github.com/BitencourtDevProjects/DockShield-Public.git
```
### Passo 2: Dar permiss√µes de execu√ß√£o para o instalador
```bash
sudo chmod u+x ./DockShield/server_b/install.sh
```
### Passo 3: Executar arquivo de instala√ß√£o
```bash
sudo ./DockShield/server_b/install.sh
```
## Web Server
O "Web Server" √© o servidor que ser√° usado para visualizar os dados obtidos via web.
### Passo 1: Clonar o reposit√≥rio
```bash
git clone https://github.com/BitencourtDevProjects/DockShield-Public.git
```
### Passo 2: Dar permiss√µes de execu√ß√£o para o instalador
```bash
sudo chmod u+x ./DockShield/server_web/install.sh
```
### Passo 3: Executar arquivo de instala√ß√£o
```bash
sudo ./DockShield/server_web/install.sh
```
---

# ‚öôÔ∏è Configura√ß√£o
Ap√≥s instalado, o projeto precisa ser configurado com informa√ß√µes espec√≠ficas que variam de usu√°rio para usu√°rio. Como endere√ßos IP e Chaves de API.
## Server A
### Passo 1: Abra as configura√ß√µes do Server A
```bash
sudo nano /etc/dock_transporter/config.ini
```
### Passo 2: Edite o arquivo config.ini
```ini
[SERVER]
host = 192.168.0.1
port = 8000
```
- **host:** Coloque o `IP` do Server B
- **port:** Pode manter o padr√£o `8000`, a menos que exista um motivo espec√≠fico para alterar.
### Passo 3: Recarregue o servi√ßo para aplicar as configura√ß√µes
```bash
sudo systemctl restart dock_transporter.service
sudo systemctl daemon-reload
```
## Server B
### Passo 1: Abra as configura√ß√µes do Server B
```bash
sudo nano /etc/dockshield/ai_config.ini
```
### Passo 2: Edite o arquivo ai_config.ini
```ini
[AI]
api_key = 

base_url = https://api.openai.com/v1
# Gemini: https://generativelanguage.googleapis.com/v1beta/openai/
# Deepseek: https://api.deepseek.com
# OpenAI: https://api.openai.com/v1
# Grok: https://api.x.ai/v1

model = 

[NVDLIB]
api_key = 

[DATABASE]
location = 
port = 27017
```
- **[AI] api_key:** Coloque a chave de API da LLM que ser√° utilizada para an√°lise;
- **base_url:** A url atrelada a LLM que ser√° utilizada, existem exemplos no arquivo `ai_config.ini` mas recomendamos que busque a url na documenta√ß√£o da API da LLM;
- **model:** O modelo de LLM que ser√° utilizado para fazer a an√°lise;
- **[NVDLIB] api_key:** A chave de API do NVDLib
- **location:** O `IP` do servidor que est√° rodando o MongoDB
- **port:** A porta onde o MongoDB est√° escutando, por padr√£o √© a porta `27017`

### Passo 3: Recarregue o servi√ßo para aplicar as configura√ß√µes
```bash
sudo systemctl restart dockshield.service
sudo systemctl daemon-reload
```
## Web Server
### Abra as configura√ß√µes do Web Server
```bash
sudo nano /var/www/server_web/web_config.ini
```
### Passo 2: Edite o arquivo web_config.ini
```ini
[DATABASE]
collection = DockShield
location = 
port = 27017
```
- **collection:** Nome da collection onde os dados est√£o armazenados, por padr√£o √© DockShield, n√£o mecher a n√£o ser que saiba o que est√° fazendo.
- **location:** O `IP` do servidor que est√° rodando o MongoDB
- **port:** A porta onde o MongoDB est√° escutando, por padr√£o √© a porta `27017`

### Passo 3: Edite o arquivo server_web.conf
```bash
sudo nano /etc/apache2/sites-available/server_web.conf
```
Coloque o IP do seu servidor no campo `serverName`
```bash
<VirtualHost *:80>
#Coloque o Ip do seu servidor
    ServerName 192.168.0.00

    WSGIDaemonProcess server_web threads=5
    WSGIScriptAlias / /var/www/server_web/app.wsgi

    <Directory /var/www/server_web>
        Require all granted
    </Directory>

    Alias /static /var/www/server_web/static
    <Directory /var/www/server_web/static>
        Require all granted
    </Directory>

    ErrorLog ${APACHE_LOG_DIR}/server_web_error.log
    CustomLog ${APACHE_LOG_DIR}/server_web_access.log combined
</VirtualHost>
```

### Passo 3: Recarregue o servi√ßo para aplicar as configura√ß√µes
```bash
sudo systemctl restart apache2.service
sudo systemctl daemon-reload
```
---

# ü§î Como usar o DockShield?
Ap√≥s a configura√ß√£o ter sido completata basta usar esse comando no Servidor A.
```bash
sudo dock_transporter run
```


Ap√≥s isso a an√°lise ir√° inicar automaticamente

# üóÇÔ∏è Estrutura do Programa
## ‚û°Ô∏è Server A
O diret√≥rio "server_a" contem os seguintes arquivos.

### `config.ini`
√â o arquivo de configura√ß√£o do Servidor A. Aqui √© colocado o IP e a porta do servidor B.

### `dock_transporter.py`
Este script, opera como um daemon em sistemas GNU/Linux. Sua principal responsabilidade √© coletar uma lista de todas as imagens Docker presentes localmente e enviar essa lista para o Servidor B.

O script inicia estabelecendo configura√ß√µes essenciais, como a leitura de par√¢metros do arquivo `/etc/dock_transporter/config.ini` e a configura√ß√£o de um sistema de logging que registra eventos em `/var/log/dock_transporter.log`. A rotina principal √© a fun√ß√£o `coletar()`, que executa o comando docker images para listar todos os reposit√≥rios e tags de imagens locais e, em seguida, transmite essa lista por meio de uma requisi√ß√£o HTTP POST para o servidor configurado no arquivo `config.ini`. O daemon implementa o processo de daemoniza√ß√£o padr√£o do Unix, usando dois `forks` para se desanexar do terminal, e mant√©m-se ativo em um loop de espera de 60 segundos. Crucialmente, ele registra um handler de sinal para o `SIGUSR1` (para execu√ß√£o imediata da `coletar()`) e outro handler para o `SIGTERM` (para encerramento ordenado pelo systemd).

### `dock_transporter.service`
√â um arquivo `unit do systemd` que configura o servi√ßo daemon garantindo que o dock_transporter.py seja iniciado automaticamente no sistema e que seja reiniciado sempre que parar de funcionar.

### `dock_transporter.sh`
Este script em Bash funciona como uma interface de linha de comando para o daemon `dock_transporter.py`. Quando chamado com o argumento `run`, o script localiza o ID de Processo (PID) do daemon ativo lendo o arquivo `/var/run/dock_transporter.pid`. Em seguida, ele utiliza o comando `kill` para enviar o sinal `SIGUSR1` ao daemon. Este sinal, √© uma instru√ß√£o program√°tica para que o daemon execute imediatamente sua fun√ß√£o interna `coletar`, que √© respons√°vel por enviar imagens Docker para an√°lise.

### `install.sh`
Este script em Bash funciona como um instalador automatizado para o programa `Dock Transporter`.

O processo √© iniciado com a atualiza√ß√£o do gerenciador de pacotes e a instala√ß√£o de depend√™ncias, incluindo o `python3-pip`, seguido pela instala√ß√£o das bibliotecas Python listadas em `requirements.txt`. O script estabelece uma estrutura de diret√≥rios padronizada em `/opt/dock_transporter` e move os arquivos de c√≥digo-fonte (`.py`), de servi√ßo (`.service`), de controle (`.sh`) e de configura√ß√£o (`.ini`) para seus respectivos locais dentro dessa estrutura. Em seguida, as permiss√µes de execu√ß√£o e leitura s√£o ajustadas para cada arquivo. O instalador finaliza criando links simb√≥licos em diret√≥rios padr√£o do sistema (`/etc/systemd/system`, `/etc/dock_transporter`, `/usr/local/bin`) para integrar o servi√ßo e seus execut√°veis ao sistema operacional. Por fim, o daemon do systemd √© recarregado, o servi√ßo √© habilitado para iniciar automaticamente no boot e, em seguida, iniciado para entrar em execu√ß√£o.

### `requirements.txt`
Este arquivo lista as depend√™ncias externas necess√°rias para que o projeto funcione corretamente.

---

## ‚û°Ô∏è Server B
O diret√≥rio "server_b" contem os seguintes arquivos.

### `ai_config.ini`
√â o arquivo de configura√ß√£o do Servidor A.

Neste arquivo s√£o configuradas as chaves de API da LLM usada e do NIST, √© definido o modelo de LLM que ser√° usada, e √© indicado o endere√ßo IP e a porta do banco de dados.

### `api.py`

Este c√≥digo implementa uma aplica√ß√£o backend utilizando o framework **FastAPI**, projetada para automatizar a an√°lise de seguran√ßa de cont√™ineres Docker. A inicializa√ß√£o do sistema envolve a leitura de configura√ß√µes sens√≠veis e de infraestrutura a partir de um arquivo INI (`/etc/dockshield/ai_config.ini`), o estabelecimento de uma conex√£o com um banco de dados **MongoDB** e a configura√ß√£o de um cliente para a API da **OpenAI**. O sistema tamb√©m define um mecanismo de logging para registrar opera√ß√µes e erros em um arquivo de log do sistema.

O n√∫cleo operacional √© exposto atrav√©s do endpoint `/upload-image`. Quando acionado, este servi√ßo recebe uma lista de imagens Docker, utiliza comandos de sistema (via `subprocess`) para baixar (`pull`) e executar (`run`) cada imagem localmente. Em seguida, ele invoca a ferramenta de verifica√ß√£o de seguran√ßa **Trivy** para gerar um relat√≥rio detalhado de vulnerabilidades em formato JSON. Se a an√°lise do Trivy for bem-sucedida, o fluxo de processamento de dados √© transferido para a fun√ß√£o `rodar`.

A fase de processamento de dados integra intelig√™ncia artificial e consultas a bases externas. Primeiramente, os metadados do relat√≥rio Trivy s√£o enviados ao modelo de linguagem (LLM) para gerar um **resumo contextual do cen√°rio** do cont√™iner, que √© salvo no MongoDB. Posteriormente, o c√≥digo extrai recursivamente todos os identificadores de vulnerabilidade (**CVEs**) √∫nicos do relat√≥rio. Para cada CVE, o sistema consulta a API do **NIST NVD** (National Vulnerability Database) para obter dados t√©cnicos oficiais.

Finalmente, ocorre uma etapa de enriquecimento de dados onde as informa√ß√µes t√©cnicas da CVE (filtradas para reduzir o consumo de tokens) s√£o enviadas novamente √† LLM. O modelo atua como um especialista em seguran√ßa, fornecendo uma an√°lise de risco, vetores de ataque e sugest√µes de mitiga√ß√£o. O registro completo, contendo os dados brutos do NVD e a an√°lise interpretativa da IA, √© armazenado em uma cole√ß√£o do MongoDB espec√≠fica para a imagem analisada, completando o ciclo de auditoria.

### `dockshield.service`
Este arquivo configura um servi√ßo do **systemd** para gerenciar a execu√ß√£o cont√≠nua da API do DockShield. Ele assegura que a aplica√ß√£o inicie via script Bash ap√≥s a rede estar dispon√≠vel, implementa uma pol√≠tica de **reinicializa√ß√£o autom√°tica** em caso de falhas e redireciona toda a sa√≠da de dados e erros para o arquivo de log `/var/log/dockshield.log`.

### `dockshield_start.sh`
Este script Bash √© o ponto de entrada (`ExecStart`) que o servi√ßo **systemd** utiliza para iniciar o DockShield. A sua fun√ß√£o √©, primeiramente, navegar para o diret√≥rio de trabalho da aplica√ß√£o (`/opt/dockshield`) e, em seguida, executar o servidor ASGI **`uvicorn`**. O servidor √© instru√≠do a carregar o objeto `app` (a inst√¢ncia FastAPI) a partir do m√≥dulo `api.py`, disponibilizando a API em todas as interfaces de rede (`0.0.0.0`) atrav√©s da porta `8000` com um √∫nico processo de trabalho.

### `install.sh`
Este script em Bash executa a instala√ß√£o automatizada da plataforma DockShield, iniciando pela aquisi√ß√£o do bin√°rio do Trivy e das depend√™ncias Python listadas. A organiza√ß√£o estrutural √© centralizada no diret√≥rio base `/opt/dockshield`, onde s√£o criados subdiret√≥rios espec√≠ficos: `relatorios` para outputs de an√°lise, `imagens` para armazenamento tempor√°rio, `config` para arquivos de parametriza√ß√£o e `bin` para scripts execut√°veis. O instalador distribui os arquivos da aplica√ß√£o, posicionando o c√≥digo-fonte principal `api.py`, bem como a unidade `dockshield.service`, na raiz do diret√≥rio base, enquanto aloca o script de inicializa√ß√£o `dockshield_start.sh` no subdiret√≥rio `bin` e o arquivo `ai_config.ini` no subdiret√≥rio `config`. A integra√ß√£o final com o sistema operacional √© consolidada atrav√©s de links simb√≥licos que conectam o arquivo de servi√ßo ao diret√≥rio do systemd em `/etc/systemd/system`, exp√µem o arquivo de configura√ß√£o em `/etc/dockshield` e tornam o execut√°vel acess√≠vel globalmente via `/usr/local/bin`, permitindo a ativa√ß√£o imediata do servi√ßo.

### `requirements.txt`
Este arquivo lista as depend√™ncias externas necess√°rias para que o projeto funcione corretamente.

---

## ‚û°Ô∏è Web Server
O diret√≥rio "server_web" contem os seguintes arquivos e diret√≥rios.

### `static/`
Cont√©m o arquivo `style.css` que define a apar√™ncia da p√°gina web.

### `templates/`
Cont√©m os arquivos `cve.html`, `docker.html`, `index.html` e `relatorio.html` que definem a estrutura da p√°gina web.

### `app.py`
A aplica√ß√£o web √© inicializada atrav√©s do framework Flask, sendo as configura√ß√µes de infraestrutura lidas a partir do arquivo `/var/www/server_web/web_config.ini`. A conex√£o com o banco de dados MongoDB √© estabelecida utilizando-se os par√¢metros de local e porta extra√≠dos do arquivo de configura√ß√£o; caso a comunica√ß√£o com o banco seja confirmada atrav√©s de um comando de "ping", a inst√¢ncia do banco de dados √© atribu√≠da, caso contr√°rio, a vari√°vel de conex√£o √© definida como nula para evitar falhas cr√≠ticas imediatas.

Na rota raiz, os nomes das cole√ß√µes existentes no banco de dados s√£o listados e enviados para serem renderizados pelo template `index.html`. Para a visualiza√ß√£o dos detalhes de uma imagem Docker espec√≠fica, √© acessada a rota `/docker/<colecao>`, onde √© buscado um documento que contenha a chave de an√°lise do cont√™iner. O conte√∫do dessa an√°lise, originalmente armazenado em formato Markdown dentro da resposta da IA, √© convertido para HTML e apresentado ao usu√°rio atrav√©s do template `docker.html`.

A listagem das vulnerabilidades (CVEs) √© gerenciada pela rota `/cve-list`, onde √© implementada uma l√≥gica de pagina√ß√£o para limitar a exibi√ß√£o a 100 itens por p√°gina. Os documentos de CVE s√£o recuperados da cole√ß√£o especificada, com seus identificadores √∫nicos sendo convertidos para string, e s√£o encaminhados para o template `cve.html` juntamente com os c√°lculos de total de p√°ginas e documentos. Detalhes espec√≠ficos de uma vulnerabilidade s√£o acessados na rota de resumo, onde o relat√≥rio da IA √© convertido de Markdown para HTML e renderizado em `relatorio.html`, sendo a aplica√ß√£o executada ao final com par√¢metros de host e porta definidos pelo ambiente ou por valores padr√£o.

### `app_sem_instala√ß√£o.py`
Este c√≥digo opera de forma an√°loga ao m√≥dulo principal `app.py`, mas √© configurado para ser executado em um ambiente local, utilizando o servidor de desenvolvimento embutido do pr√≥prio framework Flask, ao inv√©s de ser gerenciado por um servidor web de produ√ß√£o como o Apache. Esta vers√£o √© destinada exclusivamente para a realiza√ß√£o de testes e depura√ß√£o de funcionalidades, n√£o sendo a implementa√ß√£o utilizada na aplica√ß√£o final.

### `app.wsgi`
Este arquivo √© utilizado por um servidor WSGI (Web Server Gateway Interface) para inicializar e hospedar a aplica√ß√£o web. O ambiente de execu√ß√£o √© preparado pela inser√ß√£o do diret√≥rio raiz da aplica√ß√£o (`/var/www/server_web`) no caminho de busca de m√≥dulos do sistema (`sys.path`), garantindo que os m√≥dulos internos sejam localizados corretamente pelo Python. A seguir, o objeto principal da aplica√ß√£o Flask, que est√° definido no m√≥dulo `app`, √© importado e renomeado para **`application`**. Este nome √© o padr√£o pelo qual a aplica√ß√£o √© disponibilizada e acessada pelo servidor WSGI hospedeiro.

### `install.sh`
Este script em Bash atua como uma ferramenta de implanta√ß√£o automatizada para a aplica√ß√£o web em um ambiente de servidor Apache (baseado em Debian/Ubuntu, dado o uso do `apt`). O processo √© iniciado com a instala√ß√£o dos pacotes do sistema, incluindo o servidor Apache, o m√≥dulo `mod_wsgi` (necess√°rio para interfacear o Python com o servidor web) e o gerenciador `pip`. Em seguida, o ambiente Python √© preparado globalmente, removendo pacotes conflitantes e instalando as depend√™ncias do projeto listadas em `requirements.txt`.

Os arquivos da aplica√ß√£o s√£o ent√£o copiados para o diret√≥rio de produ√ß√£o `/var/www/server_web`, onde a propriedade √© transferida para o usu√°rio `www-data` e as permiss√µes s√£o ajustadas para garantir o acesso pelo servidor web. A configura√ß√£o do Virtual Host √© integrada ao Apache movendo-se o arquivo `.conf` para o diret√≥rio de sites dispon√≠veis, e um arquivo de log dedicado √© criado com permiss√µes de escrita espec√≠ficas. A implanta√ß√£o √© conclu√≠da com a ativa√ß√£o do site atrav√©s do comando `a2ensite` e o recarregamento do servi√ßo Apache.

### `server_web.conf`
Este arquivo de configura√ß√£o define um **Virtual Host** no servidor **Apache HTTP** para a aplica√ß√£o web, expondo-a na porta 80. Sua principal fun√ß√£o √© atuar como a ponte final, gerenciando o tr√°fego de entrada e direcionando-o corretamente.

A execu√ß√£o da aplica√ß√£o Python √© orquestrada pelo m√≥dulo **`mod_wsgi`**. A diretiva **`WSGIDaemonProcess`** cria um ambiente isolado e dedicado (`server_web`) para o c√≥digo Python, e o **`WSGIScriptAlias`** mapeia todas as requisi√ß√µes recebidas para o arquivo de *gateway* da aplica√ß√£o (**`app.wsgi`**). Al√©m disso, o Apache √© configurado para servir diretamente os **arquivos est√°ticos** (`/static`) da aplica√ß√£o, liberando o processo WSGI dessa tarefa, e estabelece caminhos dedicados para os logs de acesso e erro do *Virtual Host*.

### `web_config.ini`
√â o arquivo de configura√ß√£o que cont√©m as informa√ß√µes para se conectar ao banco de dados onde os ralat√≥rios est√£o.

### `requirements.txt` 
Este arquivo lista as depend√™ncias externas necess√°rias para que o projeto funcione corretamente.

#  üòÉ Autores
 - [Mateus Brito Bitencourt](https://github.com/M-Bitencourt)
 - [Gabriel Brito Bitencourt](https://github.com/G-Bitencourt)

# üìù Licen√ßa
Distribu√≠do sob a licen√ßa **AGPLv3**. Veja o arquivo `LICENSE` no reposit√≥rio para mais informa√ß√µes.

